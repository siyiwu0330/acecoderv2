# Parquet è½¬æ¢å·¥å…·ä½¿ç”¨è¯´æ˜

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

`convert_to_parquet.py` æ˜¯ä¸€ä¸ªåŸºäº `hf_dataset_converter.py` é€»è¾‘çš„æ•°æ®è½¬æ¢å·¥å…·ï¼Œå°† AceCoderV2 çš„ JSONL æ ¼å¼æ•°æ®è½¬æ¢ä¸º Parquet æ ¼å¼ï¼Œä¾¿äºé«˜æ•ˆå­˜å‚¨å’ŒåŠ è½½ã€‚

## ğŸš€ ä¸»è¦ç‰¹æ€§

- âœ… **æ™ºèƒ½æ•°æ®æå–**ï¼šä» `synthesis_result` ä¸­æå–ç”Ÿæˆçš„å¤æ‚é—®é¢˜å’Œæµ‹è¯•ç”¨ä¾‹
- âœ… **æ•°æ®éªŒè¯**ï¼šè‡ªåŠ¨éªŒè¯æ•°æ®å®Œæ•´æ€§å’Œæ ¼å¼æ­£ç¡®æ€§
- âœ… **å»é‡åˆå¹¶**ï¼šæ”¯æŒæŒ‰é—®é¢˜å†…å®¹å»é‡å’Œè·¨è½®æ¬¡åˆå¹¶
- âœ… **çµæ´»è¿‡æ»¤**ï¼šæ”¯æŒæŒ‰è½®æ¬¡ã€æœ€å°æµ‹è¯•ç”¨ä¾‹æ•°é‡ç­‰æ¡ä»¶è¿‡æ»¤
- âœ… **ç»Ÿè®¡ä¿¡æ¯**ï¼šæä¾›è¯¦ç»†çš„æ•°æ®é›†ç»Ÿè®¡å’Œåˆ†æ
- âœ… **å…ƒæ•°æ®ä¿ç•™**ï¼šå®Œæ•´ä¿ç•™å®éªŒè½®æ¬¡ã€æ¨¡å‹ä¿¡æ¯ç­‰å…ƒæ•°æ®

## ğŸ“‹ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

```bash
# åŸºæœ¬è½¬æ¢
python convert_to_parquet.py --jsonl_path data.jsonl --local_dir output_dir

# æŒ‡å®šæµ‹è¯•é›†å¤§å°
python convert_to_parquet.py --jsonl_path data.jsonl --local_dir output_dir --test_size 1000

# æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
python convert_to_parquet.py --jsonl_path data.jsonl --local_dir output_dir --stats
```

### é«˜çº§ç”¨æ³•

```bash
# åªæå–ç‰¹å®šè½®æ¬¡çš„æ•°æ®
python convert_to_parquet.py --jsonl_path data.jsonl --local_dir output_dir --target_round 3

# è®¾ç½®æœ€å°æµ‹è¯•ç”¨ä¾‹æ•°é‡
python convert_to_parquet.py --jsonl_path data.jsonl --local_dir output_dir --min_tests 5

# ç¦ç”¨å»é‡ï¼ˆä¿ç•™æ‰€æœ‰é‡å¤é¡¹ï¼‰
python convert_to_parquet.py --jsonl_path data.jsonl --local_dir output_dir --no_deduplicate

# è‡ªå®šä¹‰æŒ‡ä»¤æ¨¡æ¿
python convert_to_parquet.py --jsonl_path data.jsonl --local_dir output_dir --instruction_template "è¯·è§£å†³ä»¥ä¸‹é—®é¢˜ï¼š"
```

## ğŸ“Š å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `--jsonl_path` | str | `problems_merged.jsonl` | è¾“å…¥ JSONL æ–‡ä»¶è·¯å¾„ |
| `--local_dir` | str | `data/acecoder` | è¾“å‡ºç›®å½• |
| `--test_size` | int | `500` | æµ‹è¯•é›†å¤§å° |
| `--random_seed` | int | `69` | éšæœºç§å­ |
| `--instruction_template` | str | é»˜è®¤æ¨¡æ¿ | è‡ªå®šä¹‰æŒ‡ä»¤æ¨¡æ¿ |
| `--target_round` | int | `None` | æŒ‡å®šè½®æ¬¡ï¼ˆNone è¡¨ç¤ºæ‰€æœ‰è½®æ¬¡ï¼‰ |
| `--min_tests` | int | `1` | æœ€å°æµ‹è¯•ç”¨ä¾‹æ•°é‡ |
| `--deduplicate` | bool | `True` | æ˜¯å¦å»é‡ |
| `--stats` | bool | `True` | æ˜¯å¦æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ |

## ğŸ“ è¾“å‡ºç»“æ„

```
output_dir/
â”œâ”€â”€ train.parquet          # è®­ç»ƒé›†
â”œâ”€â”€ test.parquet           # æµ‹è¯•é›†
â””â”€â”€ metadata.json          # å…ƒæ•°æ®ä¿¡æ¯
```

## ğŸ” æ•°æ®æ ¼å¼

### Parquet æ–‡ä»¶ç»“æ„

æ¯è¡ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```python
{
    "data_source": "acecoderv2",
    "prompt": [
        {
            "role": "user", 
            "content": "é—®é¢˜æè¿° + æŒ‡ä»¤æ¨¡æ¿"
        }
    ],
    "ability": "code",
    "reward_model": {
        "style": "rule",
        "ground_truth": ""
    },
    "extra_info": {
        "split": "train/test",
        "index": 0,
        "id": "é—®é¢˜ID",
        "question": "åŸå§‹é—®é¢˜æè¿°",
        "test_cases": ["æµ‹è¯•ç”¨ä¾‹1", "æµ‹è¯•ç”¨ä¾‹2", ...],
        "inputs_outputs": None,
        "metadata": {
            "experiment_round": "å®éªŒè½®æ¬¡",
            "model_name": "æ¨¡å‹åç§°",
            "step_type": "æ­¥éª¤ç±»å‹",
            "content_type": "generated/original",
            "has_generated_problem": True/False,
            "num_tests": æµ‹è¯•ç”¨ä¾‹æ•°é‡,
            "num_programs": ç¨‹åºæ•°é‡,
            "eval_stats": {...}  # è¯„ä¼°ç»Ÿè®¡
        }
    }
}
```

## ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯

å·¥å…·ä¼šæä¾›ä»¥ä¸‹ç»Ÿè®¡ä¿¡æ¯ï¼š

- **åŸºæœ¬ç»Ÿè®¡**ï¼šæ€»é¡¹ç›®æ•°ã€è®­ç»ƒ/æµ‹è¯•é›†å¤§å°
- **æµ‹è¯•ç”¨ä¾‹ç»Ÿè®¡**ï¼šå¹³å‡/æœ€å°/æœ€å¤§æµ‹è¯•ç”¨ä¾‹æ•°é‡
- **è½®æ¬¡åˆ†å¸ƒ**ï¼šå„å®éªŒè½®æ¬¡çš„æ•°æ®åˆ†å¸ƒ
- **æ¨¡å‹åˆ†å¸ƒ**ï¼šå„æ¨¡å‹çš„æ•°æ®åˆ†å¸ƒ
- **å†…å®¹ç±»å‹**ï¼šç”Ÿæˆå†…å®¹ vs åŸå§‹å†…å®¹çš„æ¯”ä¾‹
- **æ ·æœ¬å±•ç¤º**ï¼šç¤ºä¾‹æ•°æ®å±•ç¤º

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### 1. æ•°æ®é¢„å¤„ç†
```bash
# å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
python convert_to_parquet.py --jsonl_path raw_data.jsonl --local_dir processed_data
```

### 2. ç‰¹å®šè½®æ¬¡åˆ†æ
```bash
# åªåˆ†æç¬¬3è½®çš„æ•°æ®
python convert_to_parquet.py --jsonl_path data.jsonl --local_dir round3_data --target_round 3
```

### 3. é«˜è´¨é‡æ•°æ®ç­›é€‰
```bash
# åªä¿ç•™æµ‹è¯•ç”¨ä¾‹æ•°é‡ >= 5 çš„æ•°æ®
python convert_to_parquet.py --jsonl_path data.jsonl --local_dir high_quality --min_tests 5
```

### 4. å¿«é€Ÿæµ‹è¯•
```bash
# å°è§„æ¨¡æµ‹è¯•
python convert_to_parquet.py --jsonl_path data.jsonl --local_dir test_data --test_size 100
```

## ğŸ”§ ä¸ hf_dataset_converter.py çš„å…³ç³»

- **æ•°æ®æå–é€»è¾‘**ï¼šå®Œå…¨ä¸€è‡´ï¼Œéƒ½ä» `synthesis_result` æå–ç”Ÿæˆçš„é—®é¢˜å’Œæµ‹è¯•ç”¨ä¾‹
- **å»é‡åˆå¹¶**ï¼šä½¿ç”¨ç›¸åŒçš„å»é‡å’Œåˆå¹¶ç®—æ³•
- **å…ƒæ•°æ®ä¿ç•™**ï¼šä¿ç•™ç›¸åŒçš„å…ƒæ•°æ®ç»“æ„
- **è¾“å‡ºæ ¼å¼**ï¼šè½¬æ¢ä¸º Parquet æ ¼å¼ï¼Œä¾¿äºé«˜æ•ˆå­˜å‚¨å’ŒåŠ è½½

## âš¡ æ€§èƒ½ä¼˜åŠ¿

- **å­˜å‚¨æ•ˆç‡**ï¼šParquet æ ¼å¼æ¯” JSON æ›´ç´§å‡‘
- **åŠ è½½é€Ÿåº¦**ï¼šParquet æ”¯æŒåˆ—å¼å­˜å‚¨ï¼ŒåŠ è½½æ›´å¿«
- **å†…å­˜å‹å¥½**ï¼šæ”¯æŒåˆ†å—è¯»å–ï¼Œé€‚åˆå¤§æ•°æ®é›†
- **å…¼å®¹æ€§**ï¼šä¸ pandasã€Dask ç­‰å·¥å…·å®Œç¾å…¼å®¹

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **æ•°æ®å®Œæ•´æ€§**ï¼šç¡®ä¿è¾“å…¥ JSONL æ–‡ä»¶åŒ…å« `synthesis_result` å­—æ®µ
2. **å†…å­˜ä½¿ç”¨**ï¼šå¤§æ•°æ®é›†å¯èƒ½éœ€è¦è¾ƒå¤šå†…å­˜
3. **æ–‡ä»¶è·¯å¾„**ï¼šç¡®ä¿è¾“å‡ºç›®å½•æœ‰å†™å…¥æƒé™
4. **ç¼–ç æ ¼å¼**ï¼šè¾“å…¥æ–‡ä»¶åº”ä¸º UTF-8 ç¼–ç 

## ğŸ“ ç¤ºä¾‹è¾“å‡º

```
âœ… Conversion completed!
ğŸ“Š Training samples: 1200
ğŸ“Š Test samples: 500
ğŸ“ Output directory: data/acecoder/processed
ğŸ“„ Train file: data/acecoder/processed/train.parquet
ğŸ“„ Test file: data/acecoder/processed/test.parquet

==================================================
ğŸ“Š DATASET STATISTICS
==================================================
Total items: 1700
Test cases per problem:
  Average: 12.5
  Min: 3
  Max: 25
Distribution by experiment round:
  round0: 200 items
  round1: 300 items
  round2: 400 items
  round3: 500 items
  round4: 300 items
Content type distribution:
  generated: 1600 items
  original: 100 items
Generated problems: 1600/1700 (94.1%)
==================================================
```

## ğŸ‰ æ€»ç»“

`convert_to_parquet.py` æ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„æ•°æ®è½¬æ¢å·¥å…·ï¼Œç‰¹åˆ«é€‚åˆå°† AceCoderV2 æ•°æ®é›†è½¬æ¢ä¸ºé«˜æ•ˆçš„ Parquet æ ¼å¼ã€‚å®ƒä¿æŒäº†ä¸ `hf_dataset_converter.py` å®Œå…¨ä¸€è‡´çš„æ•°æ®å¤„ç†é€»è¾‘ï¼ŒåŒæ—¶æä¾›äº†æ›´å¥½çš„å­˜å‚¨å’ŒåŠ è½½æ€§èƒ½ã€‚

